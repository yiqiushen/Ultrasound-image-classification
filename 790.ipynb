{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6466805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82f901",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29664d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Check if the dataset file already exists\n",
    "dataset_filename = \"breast-ultrasound-images-dataset.zip\"  # Replace with the actual filename\n",
    "\n",
    "if not os.path.exists(dataset_filename):\n",
    "    # download dataset from Kaggle if not present\n",
    "    ! pip install -q kaggle\n",
    "    files.upload()\n",
    "    # upload json file from your Kaggle account\n",
    "    ! mkdir ~/.kaggle\n",
    "    ! cp kaggle.json ~/.kaggle/\n",
    "    ! chmod 600 ~/.kaggle/kaggle.json\n",
    "    ! kaggle datasets download -d aryashah2k/breast-ultrasound-images-dataset\n",
    "else:\n",
    "    print(f\"Dataset file '{dataset_filename}' already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92448600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: if the folder Dataset_BUSI_with_GT exists then skip unzip file otherwise unzip file\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if the folder exists\n",
    "folder_name = \"Dataset_BUSI_with_GT\"\n",
    "if not os.path.exists(folder_name):\n",
    "    # Unzip the file if the folder doesn't exist\n",
    "    !unzip breast-ultrasound-images-dataset.zip\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists. Skipping unzip.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61057d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: build training testing validation set using data in the folder dataset_busi_with_gt, each data point is a photo, label is the folder name benign, malignant, normal. we only need data that does not end with _mask.png\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define data directory\n",
    "data_dir = 'Dataset_BUSI_with_GT'\n",
    "\n",
    "# Define image extensions to consider\n",
    "image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images_and_labels(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_to_idx = {}\n",
    "    idx_to_class = {}\n",
    "    current_idx = 0\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_to_idx[class_name] = current_idx\n",
    "            idx_to_class[current_idx] = class_name\n",
    "            current_idx += 1\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.lower().endswith(image_extensions) and not filename.lower().endswith('_mask.png'):\n",
    "                    img_path = os.path.join(class_dir, filename)\n",
    "                    try:\n",
    "                        image = Image.open(img_path)\n",
    "                        images.append((image, class_name))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "    return images, class_to_idx, idx_to_class\n",
    "\n",
    "# Load images and labels\n",
    "images, class_to_idx, idx_to_class = load_images_and_labels(data_dir)\n",
    "\n",
    "# Split data\n",
    "train_val_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "train_images, val_images = train_test_split(train_val_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate images and labels\n",
    "train_images, train_labels = zip(*train_images)\n",
    "val_images, val_labels = zip(*val_images)\n",
    "test_images, test_labels = zip(*test_images)\n",
    "\n",
    "# Map class names to indices for labels\n",
    "train_labels = [class_to_idx[label] for label in train_labels]\n",
    "val_labels = [class_to_idx[label] for label in val_labels]\n",
    "test_labels = [class_to_idx[label] for label in test_labels]\n",
    "\n",
    "# Print split sizes\n",
    "print(f\"Train set size: {len(train_images)}, Labels: {len(train_labels)}\")\n",
    "print(f\"Validation set size: {len(val_images)}, Labels: {len(val_labels)}\")\n",
    "print(f\"Test set size: {len(test_images)}, Labels: {len(test_labels)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280583b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: classify the above dataset using imagenet\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained ResNet model (you can choose other models too)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the image transformations for ImageNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to classify a single image\n",
    "def classify_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img_t = transform(img)\n",
    "        batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(batch_t)\n",
    "\n",
    "        _, index = torch.max(out, 1)\n",
    "\n",
    "        # Load ImageNet class labels\n",
    "        with open('imagenet_classes.txt') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "        # Print top 5 predictions\n",
    "        _, indices = torch.sort(out, descending=True)\n",
    "        for idx in indices[0][:5]:\n",
    "            print(f\"{classes[idx]}: {percentage[idx].item():.2f}%\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Example usage: Classify an image from the dataset\n",
    "# You'll need to replace 'path/to/your/image.jpg' with the actual path to an image\n",
    "# from the dataset.\n",
    "\n",
    "# Example image path\n",
    "image_path_example = os.path.join(data_dir, \"benign\", \"benign (1).png\")\n",
    "\n",
    "# Download the imagenet class labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "\n",
    "classify_image(image_path_example)\n",
    "\n",
    "\n",
    "# To classify multiple images, you can iterate through your image list:\n",
    "# for image_path in your_image_list:\n",
    "#    classify_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d021211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = CustomDataset(train_images, train_labels, transform)\n",
    "val_dataset = CustomDataset(val_images, val_labels, transform)\n",
    "test_dataset = CustomDataset(test_images, test_labels, transform)\n",
    "\n",
    "# Prepare data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load a pretrained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes\n",
    "num_classes = len(class_to_idx)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# Test phase\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9deeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define a custom dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure images are grayscale\n",
    "    transforms.Resize((256, 256)),  # Resize to 256x256\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize for 1 channel\n",
    "])\n",
    "# Create datasets\n",
    "train_dataset = CustomImageDataset(train_images, train_labels, transform=transform)\n",
    "val_dataset = CustomImageDataset(val_images, val_labels, transform=transform)\n",
    "test_dataset = CustomImageDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a simple CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Change input channels to 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 64 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "num_classes = len(class_to_idx)\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.float(), labels\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        val_accuracy, val_loss = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.float(), labels\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, val_loss / len(data_loader)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Test the model\n",
    "test_accuracy, _ = evaluate_model(model, test_loader, criterion)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with image resized to 128*128\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define a custom dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure images are grayscale\n",
    "    transforms.Resize((128, 128)),  # Resize to 256x256\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize for 1 channel\n",
    "])\n",
    "# Create datasets\n",
    "train_dataset = CustomImageDataset(train_images, train_labels, transform=transform)\n",
    "val_dataset = CustomImageDataset(val_images, val_labels, transform=transform)\n",
    "test_dataset = CustomImageDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a simple CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Change input channels to 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 32 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "num_classes = len(class_to_idx)\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.float(), labels\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        val_accuracy, val_loss = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.float(), labels\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, val_loss / len(data_loader)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Test the model\n",
    "test_accuracy, _ = evaluate_model(model, test_loader, criterion)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DeeperCNN, self).__init__()\n",
    "\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = None  # Placeholder for dynamic initialization\n",
    "        self.fc2 = None  # Placeholder for dynamic initialization\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Output layer\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Dynamically initialize fully connected layers based on input size\n",
    "        if self.fc1 is None:\n",
    "            flattened_size = x.view(x.size(0), -1).size(1)\n",
    "            self.fc1 = nn.Linear(flattened_size, 512).to(x.device)\n",
    "            self.fc2 = nn.Linear(512, self.num_classes).to(x.device)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f089f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_to_idx)\n",
    "model = DeeperCNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c880f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load the CLIP model and processor\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9890586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load the CLIP model and processor\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa311a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def zero_shot_classify(image_paths, class_labels):\n",
    "    results = {}\n",
    "    for img_path in image_paths:\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Process the image and text labels\n",
    "        inputs = processor(\n",
    "            text=class_labels,\n",
    "            images=image,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "        ).to(device)\n",
    "\n",
    "        # Perform classification\n",
    "        outputs = model(**inputs)\n",
    "        logits_per_image = outputs.logits_per_image  # Image-to-text similarity scores\n",
    "        probabilities = logits_per_image.softmax(dim=1)\n",
    "\n",
    "        # Store probabilities\n",
    "        results[img_path] = {label: prob.item() for label, prob in zip(class_labels, probabilities[0])}\n",
    "\n",
    "    return results\n",
    "\n",
    "# Dynamically generate test image paths based on dataset structure\n",
    "test_image_paths = [\n",
    "    os.path.join(data_dir, idx_to_class[label], img.filename) for img, label in zip(test_images, test_labels)\n",
    "]\n",
    "\n",
    "# Define class labels (replace with your actual class labels)\n",
    "class_labels = list(class_to_idx.keys()) # Get class labels from class_to_idx dictionary\n",
    "\n",
    "# Perform zero-shot classification\n",
    "zero_shot_results = zero_shot_classify(test_image_paths, class_labels)\n",
    "\n",
    "# Print results\n",
    "for img_path, probs in zero_shot_results.items():\n",
    "    print(f'Results for {img_path}:')\n",
    "    for label, prob in probs.items():\n",
    "        print(f'  {label}: {prob:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels can be replaced by more descriptive langauage\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a mapping from numerical indices to the new descriptive labels\n",
    "idx_to_new_label = {\n",
    "    0: 'an ultrasonic image of normal breast tissue',\n",
    "    1: 'an ultrasonic image of benign breast tumor',\n",
    "    2: 'an ultrasonic image of malignant breast tumor',\n",
    "}\n",
    "\n",
    "# Convert the numerical labels in train/val/test datasets to the new descriptive labels\n",
    "train_labels_new = [idx_to_new_label[label] for label in train_labels]\n",
    "val_labels_new = [idx_to_new_label[label] for label in val_labels]\n",
    "test_labels_new = [idx_to_new_label[label] for label in test_labels]\n",
    "\n",
    "\n",
    "# Now, use these new labels when creating your datasets:\n",
    "\n",
    "# Create datasets with new labels\n",
    "train_dataset = CustomDataset(train_images, train_labels_new, transform=transform)\n",
    "val_dataset = CustomDataset(val_images, val_labels_new, transform=transform)\n",
    "test_dataset = CustomDataset(test_images, test_labels_new, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ad21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_to_idx = {label: idx for idx, label in enumerate(class_labels)}\n",
    "class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd87540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: label the test data by the highest probability and calculate the test error\n",
    "\n",
    "# Function to label test data and calculate test error\n",
    "def label_and_evaluate(zero_shot_results, test_labels, class_to_idx):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(test_labels)\n",
    "    predicted_labels = []\n",
    "\n",
    "    for img_path, probs in zero_shot_results.items():\n",
    "        # Find the class label with the highest probability\n",
    "        predicted_label = max(probs, key=probs.get)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "        # Convert predicted label to numerical index\n",
    "        try:\n",
    "            predicted_label_index = list(class_to_idx.keys()).index(predicted_label)\n",
    "        except ValueError:\n",
    "          print(f\"Warning: Predicted label '{predicted_label}' not found in class_to_idx. Skipping.\")\n",
    "          continue\n",
    "\n",
    "        # Get the true label for the current image\n",
    "        # Assuming test_labels contains numerical indices corresponding to class_to_idx\n",
    "        true_label_index = test_labels[list(zero_shot_results.keys()).index(img_path)]\n",
    "\n",
    "        if predicted_label_index == true_label_index:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    test_error = 1 - (correct_predictions / total_predictions)\n",
    "    print(f\"Test Error: {test_error:.4f}\")\n",
    "    return test_error\n",
    "\n",
    "\n",
    "# Assuming you have test_labels and class_to_idx defined\n",
    "predicted_labels = label_and_evaluate(zero_shot_results, test_labels, class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f393ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Transformations for training and validation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = CustomDataset(train_images, train_labels, transform)\n",
    "val_dataset = CustomDataset(val_images, val_labels, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the CLIP model and processor\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "# Modify the CLIP model for fine-tuning\n",
    "vision_model = model.vision_model  # Use only the vision encoder\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# Modify the CLIP model for fine-tuning\n",
    "vision_model = model.vision_model  # Use only the vision encoder\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# Get the output size of the vision model\n",
    "with torch.no_grad():\n",
    "    output_size = vision_model(torch.randn(1, 3, 224, 224).to(device)).pooler_output.shape[1]\n",
    "\n",
    "# Add a new classification head with the correct input size\n",
    "classifier = nn.Linear(output_size, num_classes)\n",
    "vision_model.classifier = classifier.to(device)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Fine-tuning loop\n",
    "num_epochs = 10\n",
    "vision_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = vision_model(images)\n",
    "        outputs = vision_model.classifier(outputs.pooler_output) # Extract pooler_output\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Validation loop\n",
    "    vision_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = vision_model(images)\n",
    "            outputs = vision_model.classifier(outputs.pooler_output)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "          f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save(vision_model.state_dict(), \"clip_fine_tuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ef7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: print out the label predicted on the test set, the true label of the test set and test error based on the fine tuned model\n",
    "\n",
    "# Load the fine-tuned model\n",
    "vision_model.load_state_dict(torch.load(\"clip_fine_tuned.pth\"))\n",
    "vision_model.eval()\n",
    "\n",
    "# Create the test dataset and data loader\n",
    "test_dataset = CustomDataset(test_images, test_labels, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Perform predictions on the test set\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = vision_model(images)\n",
    "        outputs = vision_model.classifier(outputs.pooler_output)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate test error\n",
    "test_error = 1 - (correct / total)\n",
    "\n",
    "# Print the results\n",
    "print(\"Predicted Labels:\", predicted_labels)\n",
    "print(\"True Labels:\", true_labels)\n",
    "print(f\"Test Error: {test_error:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
